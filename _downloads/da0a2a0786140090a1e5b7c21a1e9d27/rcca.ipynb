{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# rCCA\nThis script shows how to use rCCA from PyntBCI for decoding c-VEP trials. The rCCA method uses a template matching\nclassifier where templates are estimated using reconvolution and canonical correlation analysis (CCA).\n\nThe data used in this script come from Thielen et al. (2021), see references [1]_ and [2]_.\n\n## References\n.. [1] Thielen et al. (2021) From full calibration to zero training for a code-modulated visual evoked potentials brain\n       computer interface. DOI: https://doi.org/10.34973/9txv-z787\n.. [2] Thielen, J., Marsman, P., Farquhar, J., & Desain, P. (2021). From full calibration to zero training for a\n       code-modulated visual evoked potentials for brain\u2013computer interface. Journal of Neural Engineering, 18(5),\n       056007. DOI: https://doi.org/10.1088/1741-2552/abecef\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn\n\nimport pyntbci\n\nseaborn.set_context(\"paper\", font_scale=1.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set the data path\nThe cell below specifies where the dataset has been downloaded to. Please, make sure it is set correctly according to\nthe specification of your device. If none of the folder structures in the dataset were changed, the cells below should\nwork just as fine.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "path = os.path.join(os.path.dirname(pyntbci.__file__))  # path to the dataset\nsubject = \"sub-01\"  # the subject to analyse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The data\nThe dataset consists of (1) the EEG data X that is a matrix of k trials, c channels, and m samples; (2) the labels y\nthat is a vector of k trials; (3) the pseudo-random noise-codes V that is a matrix of n classes and m samples. Note,\nthe codes are upsampled to match the EEG sampling frequency and contain only one code-cycle.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Load data\nfn = os.path.join(path, \"data\", f\"thielen2021_{subject}.npz\")\ntmp = np.load(fn)\nX = tmp[\"X\"]\ny = tmp[\"y\"]\nV = tmp[\"V\"]\nfs = tmp[\"fs\"]\nfr = 60\nprint(\"X\", X.shape, \"(trials x channels x samples)\")  # EEG\nprint(\"y\", y.shape, \"(trials)\")  # labels\nprint(\"V\", V.shape, \"(classes, samples)\")  # codes\nprint(\"fs\", fs, \"Hz\")  # sampling frequency\nprint(\"fr\", fr, \"Hz\")  # presentation rate\n\n# Extract data dimensions\nn_trials, n_channels, n_samples = X.shape\nn_classes = V.shape[0]\n\n# Read cap file\ncapfile = os.path.join(path, \"capfiles\", \"thielen8.loc\")\nwith open(capfile, \"r\") as fid:\n    channels = []\n    for line in fid.readlines():\n        channels.append(line.split(\"\\t\")[-1].strip())\nprint(\"Channels:\", \", \".join(channels))\n\n# Visualize EEG data\ni_trial = 0  # the trial to visualize\nplt.figure(figsize=(15, 5))\nplt.plot(np.arange(0, n_samples) / fs, 25e-6 * np.arange(n_channels) + X[i_trial, :, :].T)\nplt.xlim([0, 1])  # limit to 1 second EEG data\nplt.yticks(25e-6 * np.arange(n_channels), channels)\nplt.xlabel(\"time [sec]\")\nplt.ylabel(\"channel\")\nplt.title(f\"Single-trial multi-channel EEG time-series (trial {i_trial})\")\nplt.tight_layout()\n\n# Visualize labels\nplt.figure(figsize=(15, 3))\nhist = np.histogram(y, bins=np.arange(n_classes + 1))[0]\nplt.bar(np.arange(n_classes), hist)\nplt.xticks(np.arange(n_classes))\nplt.xlabel(\"label\")\nplt.ylabel(\"count\")\nplt.title(\"Single-trial labels\")\nplt.tight_layout()\n\n# Visualize stimuli\nVup = V.repeat(20, axis=1)  # upsample to better visualize the sharp edges\nplt.figure(figsize=(15, 8))\nplt.plot(np.arange(Vup.shape[1]) / (20 * fs), 2 * np.arange(n_classes) + Vup.T)\nfor i in range(1 + int(V.shape[1] / (fs / fr))):\n    plt.axvline(i / fr, c=\"k\", alpha=0.1)\nplt.yticks(2 * np.arange(n_classes), np.arange(n_classes))\nplt.xlabel(\"time [sec]\")\nplt.ylabel(\"code\")\nplt.title(\"Code time-series\")\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The event matrix\nThe first step for reconvolution is to find within the sequences the repetitive events. This can be imposed \"manually\"\nby choosing the event definition that we believe the brain responds to. Here, the so-called \"duration\" event is used,\nwhich marks the length of a flash as the important piece of information. As the sequences in this dataset were\nmodulated, there are only two events: a short and a long flash. Additionally, a third event is added that will account\nfor the onset of a trial, during which all of a sudden the screen started flashing. The event matrix is a matrix of n\nclasses, e events, and m samples.\n\nPlease, note that more event definitions exist, which can be explored with the `event` variable of `rCCA`. For\ninstance, `event=\"contrast\"` is a useful event definition as well, which looks at rising and falling edges,\ngeneralising over the length of a flash.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create event matrix\nE, events = pyntbci.utilities.event_matrix(V, event=\"duration\", onset_event=True)\nprint(\"E:\", E.shape, \"(classes x events x samples)\")\nprint(\"Events:\", \", \".join([str(event) for event in events]))\n\n# Visualize event time-series\ni_class = 0  # the class to visualize\nfig, ax = plt.subplots(1, 1, figsize=(15, 3))\npyntbci.plotting.eventplot(V[i_class, ::int(fs/fr)], E[i_class, :, ::int(fs/fr)], fs=fr, ax=ax, events=events)\nax.set_title(f\"Event time-series (code {i_class})\")\nplt.tight_layout()\n\n# Visualize event matrix\ni_class = 0\nplt.figure(figsize=(15, 3))\nplt.imshow(E[i_class, :, :], cmap=\"gray\")\nplt.gca().set_aspect(10)\nplt.xticks(np.arange(0, E.shape[2], 60), np.arange(0, E.shape[2], 60) / fs)\nplt.yticks(np.arange(E.shape[1]), events)\nplt.xlabel(\"time [sec]\")\nplt.title(f\"Event matrix (class {i_class})\")\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The structure matrix\nThe second step for reconvolution is to model the expected responses associated to each of the events and their\noverlap. This is done in the so-called structure matrix (or design matrix). The structure matrix is essentially a\nToeplitz version of the event matrix. It allows to model the c-VEP as the dot product of r (the transient response to\nan event) and M (the structure matrix for a specific class) for the ith class. The structure matrix is a matrix of n\nclasses, l response samples, and m samples.\n\nAn important parameter here is the `encoding_length` argument. An easy abstraction is to assume the same length for\nthe responses to each of the events. However, one could also set different lengths for each of the events.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create structure matrix\nencoding_length = int(0.3 * fs)  # 300 ms responses\nM = pyntbci.utilities.structure_matrix(E, encoding_length)\nprint(\"M: shape:\", M.shape, \"(classes x encoding_length*events x samples)\")\n\n# Plot structure matrix\ni_class = 0  # the class to visualize\nplt.figure(figsize=(15, 6))\nplt.imshow(M[i_class, :, :], cmap=\"gray\")\nplt.xticks(np.arange(0, M.shape[2], 60), np.arange(0, M.shape[2], 60) / fs)\nplt.yticks(np.arange(0, E.shape[1] * encoding_length, 12), np.tile(np.arange(0, encoding_length, 12) / fs, E.shape[1]))\nplt.xlabel(\"time [sec]\")\nplt.ylabel(events[::-1])\nplt.title(f\"Structure matrix (class {i_class})\")\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reconvolution CCA\nThe full reconvolution CCA (rCCA) pipeline is implemented as a scikit-learn compatible class in PyntBCI in\n`pyntbci.classifiers.rCCA`. All it needs are the binary sequences `stimulus`, the sampling frequency `fs`, the event\ndefinition `event`, the transient response size `encoding_length` and whether or not to include an event for the onset\nof a trial `onset_event`.\n\nWhen calling `rCCA.fit(X, y)` with training data `X` and labels `y`, the full decomposition is performed to obtain\nspatial filters `rCCA.w_` and temporal filter `rCCA.r_`.\n\nPlease note that the transient responses are concatenated in this temporal filter `rCCA.r_`. One can use\n`rCCA.events_` to disentangle these and find which response is associated to which event.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Perform CCA\nencoding_length = 0.3  # 300 ms responses\nrcca = pyntbci.classifiers.rCCA(stimulus=V, fs=fs, event=\"duration\", encoding_length=encoding_length, onset_event=True)\nrcca.fit(X, y)\nprint(\"w: \", rcca.w_.shape, \"(channels)\")\nprint(\"r: \", rcca.r_.shape, \"(encoding_length*events)\")\n\n# Plot CCA filters\nfig, ax = plt.subplots(1, 2, figsize=(15, 3))\npyntbci.plotting.topoplot(rcca.w_, capfile, ax=ax[0])\nax[0].set_title(\"spatial filter\")\ntmp = np.reshape(rcca.r_, (len(rcca.events_), -1))\nfor i in range(len(rcca.events_)):\n    ax[1].plot(np.arange(int(encoding_length * fs)) / fs, tmp[i, :])\nax[1].legend(rcca.events_)\nax[1].set_xlabel(\"time [sec]\")\nax[1].set_ylabel(\"amplitude [a.u.]\")\nax[1].set_title(\"Transient responses\")\nfig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cross-validation\nTo perform decoding, one can call `rCCA.fit(X_trn, y_trn)` on training data `X_trn` and labels `y_trn` and\n`rCCA.predict(X_tst)` on testing data `X_tst`. In this section, a chronological cross-validation is setup to evaluate\nthe performance of rCCA.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trialtime = 4.2  # limit trials to a certain duration in seconds\nintertrialtime = 1.0  # ITI in seconds for computing ITR\nn_samples = int(trialtime * fs)\n\n# Chronological cross-validation\nn_folds = 5\nfolds = np.repeat(np.arange(n_folds), int(n_trials / n_folds))\n\n# Loop folds\naccuracy = np.zeros(n_folds)\nfor i_fold in range(n_folds):\n    # Split data to train and test set\n    X_trn, y_trn = X[folds != i_fold, :, :n_samples], y[folds != i_fold]\n    X_tst, y_tst = X[folds == i_fold, :, :n_samples], y[folds == i_fold]\n\n    # Train template-matching classifier\n    rcca = pyntbci.classifiers.rCCA(stimulus=V, fs=fs, event=\"duration\", encoding_length=0.3, onset_event=True)\n    rcca.fit(X_trn, y_trn)\n\n    # Apply template-matching classifier\n    yh_tst = rcca.predict(X_tst)\n\n    # Compute accuracy\n    accuracy[i_fold] = np.mean(yh_tst == y_tst)\n\n# Compute ITR\nitr = pyntbci.utilities.itr(n_classes, accuracy, trialtime + intertrialtime)\n\n# Plot accuracy (over folds)\nplt.figure(figsize=(15, 3))\nplt.bar(np.arange(n_folds), accuracy)\nplt.axhline(accuracy.mean(), linestyle='--', alpha=0.5, label=\"average\")\nplt.axhline(1 / n_classes, color=\"k\", linestyle=\"--\", alpha=0.5, label=\"chance\")\nplt.xlabel(\"(test) fold\")\nplt.ylabel(\"accuracy\")\nplt.legend()\nplt.title(\"Chronological cross-validation\")\nplt.tight_layout()\n\n# Print accuracy (average and standard deviation over folds)\nprint(f\"Accuracy: avg={accuracy.mean():.2f} with std={accuracy.std():.2f}\")\nprint(f\"ITR: avg={itr.mean():.1f} with std={itr.std():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Learning curve\nIn this section, we will apply the decoder to varying number of training trials, to estimate a so-called learning\ncurve. With this information, one could decide how much training data is required, or compare algorithms on how much\ntraining data they require to estimate their parameters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trialtime = 4.2  # limit trials to a certain duration in seconds\nn_samples = int(trialtime * fs)\n\n# Chronological cross-validation\nn_folds = 5\nfolds = np.repeat(np.arange(n_folds), int(n_trials / n_folds))\n\n# Set learning curve axis\ntrain_trials = np.arange(1, 1 + np.sum(folds != 0))\nn_train_trials = train_trials.size\n\n# Loop folds\naccuracy = np.zeros((n_folds, n_train_trials))\nfor i_fold in range(n_folds):\n\n    # Split data to train and test set\n    X_trn, y_trn = X[folds != i_fold, :, :n_samples], y[folds != i_fold]\n    X_tst, y_tst = X[folds == i_fold, :, :n_samples], y[folds == i_fold]\n\n    # Loop train trials\n    for i_trial in range(n_train_trials):\n        # Train classifier\n        rcca = pyntbci.classifiers.rCCA(stimulus=V, fs=fs, event=\"duration\", encoding_length=0.3, onset_event=True)\n        rcca.fit(X_trn[:train_trials[i_trial], :, :], y_trn[:train_trials[i_trial]])\n\n        # Apply classifier\n        yh_tst = rcca.predict(X_tst)\n\n        # Compute accuracy\n        accuracy[i_fold, i_trial] = np.mean(yh_tst == y_tst)\n\n# Plot results\nplt.figure(figsize=(15, 3))\navg = accuracy.mean(axis=0)\nstd = accuracy.std(axis=0)\nplt.plot(train_trials * trialtime, avg, linestyle='-', marker='o', label=\"rCCA\")\nplt.fill_between(train_trials * trialtime, avg + std, avg - std, alpha=0.2, label=\"_rCCA\")\nplt.axhline(1 / n_classes, color=\"k\", linestyle=\"--\", alpha=0.5, label=\"chance\")\nplt.xlabel(\"learning time [sec]\")\nplt.ylabel(\"accuracy\")\nplt.legend()\nplt.title(\"Learning curve\")\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Decoding curve\nIn this section, we will apply the decoder to varying testing trial lengths, to estimate a so-called decoding curve.\nWith this information, one could decide how much testing data is required, or compare algorithms on how much data they\nneed during testing to classify single-trials.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trialtime = 4.2  # limit trials to a certain duration in seconds\nintertrialtime = 1.0  # ITI in seconds for computing ITR\nn_samples = int(trialtime * fs)\n\n# Chronological cross-validation\nn_folds = 5\nfolds = np.repeat(np.arange(n_folds), int(n_trials / n_folds))\n\n# Set decoding curve axis\nsegmenttime = 0.1  # step size of the decoding curve in seconds\nsegments = np.arange(segmenttime, trialtime, segmenttime)\nn_segments = segments.size\n\n# Loop folds\naccuracy = np.zeros((n_folds, n_segments))\nfor i_fold in range(n_folds):\n\n    # Split data to train and test set\n    X_trn, y_trn = X[folds != i_fold, :, :n_samples], y[folds != i_fold]\n    X_tst, y_tst = X[folds == i_fold, :, :n_samples], y[folds == i_fold]\n\n    # Setup classifier\n    rcca = pyntbci.classifiers.rCCA(stimulus=V, fs=fs, event=\"duration\", encoding_length=0.3, onset_event=True)\n\n    # Train classifier\n    rcca.fit(X_trn, y_trn)\n\n    # Loop segments\n    for i_segment in range(n_segments):\n        # Apply classifier\n        yh_tst = rcca.predict(X_tst[:, :, :int(fs * segments[i_segment])])\n\n        # Compute accuracy\n        accuracy[i_fold, i_segment] = np.mean(yh_tst == y_tst)\n\n# Compute ITR\ntime = np.tile(segments[np.newaxis, :], (n_folds, 1))\nitr = pyntbci.utilities.itr(n_classes, accuracy, time + intertrialtime)\n\n# Plot results\nfig, ax = plt.subplots(2, 1, figsize=(15, 5), sharex=True)\navg = accuracy.mean(axis=0)\nstd = accuracy.std(axis=0)\nax[0].plot(segments, avg, linestyle='-', marker='o', label=\"rCCA\")\nax[0].fill_between(segments, avg + std, avg - std, alpha=0.2, label=\"_rCCA\")\nax[0].axhline(1 / n_classes, color=\"k\", linestyle=\"--\", alpha=0.5, label=\"chance\")\navg = itr.mean(axis=0)\nstd = itr.std(axis=0)\nax[1].plot(segments, avg, linestyle='-', marker='o', label=\"rCCA\")\nax[1].fill_between(segments, avg + std, avg - std, alpha=0.2, label=\"_rCCA\")\nax[1].set_xlabel(\"decoding time [sec]\")\nax[0].set_ylabel(\"accuracy\")\nax[1].set_ylabel(\"ITR [bits/min]\")\nax[0].legend()\nax[0].set_title(\"Decoding curve\")\nfig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyse multiple participants\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set paths\npath = os.path.join(os.path.dirname(pyntbci.__file__))\nn_subjects = 5\nsubjects = [f\"sub-{1 + i:02d}\" for i in range(n_subjects)]\n\n# Set trial duration\ntrialtime = 4.2  # limit trials to a certain duration in seconds\nn_trials = 100  # limit the number of trials in the dataset\n\n# Chronological cross-validation\nn_folds = 5\nfolds = np.repeat(np.arange(n_folds), int(n_trials / n_folds))\n\n# Loop participants\naccuracy = np.zeros((n_subjects, n_folds))\nfor i_subject in range(n_subjects):\n    subject = subjects[i_subject]\n\n    # Load data\n    fn = os.path.join(path, \"data\", f\"thielen2021_{subject}.npz\")\n    tmp = np.load(fn)\n    fs = tmp[\"fs\"]\n    X = tmp[\"X\"][:n_trials, :, :int(trialtime * fs)]\n    y = tmp[\"y\"][:n_trials]\n    V = tmp[\"V\"]\n\n    # Cross-validation\n    for i_fold in range(n_folds):\n        # Split data to train and test set\n        X_trn, y_trn = X[folds != i_fold, :, :], y[folds != i_fold]\n        X_tst, y_tst = X[folds == i_fold, :, :], y[folds == i_fold]\n\n        # Train classifier\n        rcca = pyntbci.classifiers.rCCA(stimulus=V, fs=fs, event=\"duration\", encoding_length=0.3, onset_event=True)\n        rcca.fit(X_trn, y_trn)\n\n        # Apply classifier\n        yh_tst = rcca.predict(X_tst)\n\n        # Compute accuracy\n        accuracy[i_subject, i_fold] = np.mean(yh_tst == y_tst)\n\n# Add average to accuracies\nsubjects += [\"avg\"]\navg = np.mean(accuracy, axis=0, keepdims=True)\naccuracy = np.concatenate((accuracy, avg), axis=0)\n\n# Plot accuracy\nplt.figure(figsize=(15, 5))\navg = accuracy.mean(axis=1)\nstd = accuracy.std(axis=1)\nplt.bar(np.arange(1 + n_subjects) + 0.3, avg, 0.5, yerr=std, label=\"rCCA\")\nplt.axhline(accuracy.mean(), linestyle=\"--\", alpha=0.5, label=\"average\")\nplt.axhline(1 / n_classes, linestyle=\"--\", color=\"k\", alpha=0.5, label=\"chance\")\nplt.table(cellText=[np.round(avg, 2), np.round(std, 2)], loc='bottom', rowLabels=[\"avg\", \"std\"], colLabels=subjects,\n          cellLoc=\"center\")\nplt.subplots_adjust(left=0.2, bottom=0.2)\nplt.xticks([])\nplt.ylabel(\"accuracy\")\nplt.xlim([-0.25, n_subjects + 0.75])\nplt.legend()\nplt.title(\"Decoding performance full dataset\")\nplt.tight_layout()\n\n# Print accuracy\nprint(f\"Average accuracy: {avg.mean():.2f}\")\n\n# plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}