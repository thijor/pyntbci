{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Epoch CCA and LDA\nThis script shows how to use CCA and LDA on epochs within a trial, using PyntBCI, for decoding c-VEP trials. Epochs are\ndefined as the windows of data within a trial, synchronized to the onset of individual flashes. For each of these epochs\nthe classifier determines whether a flash was presented or not. Integrating that information over time, allows the\ndecoding of trials.\n\nThe data used in this script come from Thielen et al. (2021), see references [1]_ and [2]_.\n\n## References\n.. [1] Thielen et al. (2021) From full calibration to zero training for a code-modulated visual evoked potentials brain\n       computer interface. DOI: https://doi.org/10.34973/9txv-z787\n.. [2] Thielen, J., Marsman, P., Farquhar, J., & Desain, P. (2021). From full calibration to zero training for a\n       code-modulated visual evoked potentials for brain\u2013computer interface. Journal of Neural Engineering, 18(5),\n       056007. DOI: https://doi.org/10.1088/1741-2552/abecef\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn\nfrom mne.decoding import Vectorizer\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.pipeline import make_pipeline\n\nimport pyntbci\n\nseaborn.set_context(\"paper\", font_scale=1.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set the data path\nThe cell below specifies where the dataset has been downloaded to. Please, make sure it is set correctly according to\nthe specification of your device. If none of the folder structures in the dataset were changed, the cells below should\nwork just as fine.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "path = os.path.join(os.path.dirname(pyntbci.__file__))  # path to the dataset\nsubject = \"sub-01\"  # the subject to analyse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The data\nThe dataset consists of (1) the EEG data X that is a matrix of k trials, c channels, and m samples; (2) the labels y\nthat is a vector of k trials; (3) the pseudo-random noise-codes V that is a matrix of n classes and m samples. Note,\nthe codes are upsampled to match the EEG sampling frequency and contain only one code-cycle.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Load data\nfn = os.path.join(path, \"data\", f\"thielen2021_{subject}.npz\")\ntmp = np.load(fn)\nX = tmp[\"X\"]\ny = tmp[\"y\"]\nV = tmp[\"V\"]\nfs = tmp[\"fs\"]\nfr = 60\nprint(\"X\", X.shape, \"(trials x channels x samples)\")  # EEG\nprint(\"y\", y.shape, \"(trials)\")  # labels\nprint(\"V\", V.shape, \"(classes, samples)\")  # codes\nprint(\"fs\", fs, \"Hz\")  # sampling frequency\nprint(\"fr\", fr, \"Hz\")  # presentation rate\n\n# Extract data dimensions\nn_trials, n_channels, n_samples = X.shape\nn_classes = V.shape[0]\n\n# Read cap file\ncapfile = os.path.join(path, \"capfiles\", \"thielen8.loc\")\nwith open(capfile, \"r\") as fid:\n    channels = []\n    for line in fid.readlines():\n        channels.append(line.split(\"\\t\")[-1].strip())\nprint(\"Channels:\", \", \".join(channels))\n\n# Visualize EEG data\ni_trial = 0  # the trial to visualize\nplt.figure(figsize=(15, 5))\nplt.plot(np.arange(0, n_samples) / fs, 25e-6 * np.arange(n_channels) + X[i_trial, :, :].T)\nplt.xlim([0, 1])  # limit to 1 second EEG data\nplt.yticks(25e-6 * np.arange(n_channels), channels)\nplt.xlabel(\"time [sec]\")\nplt.ylabel(\"channel\")\nplt.title(f\"Single-trial multi-channel EEG time-series (trial {i_trial})\")\nplt.tight_layout()\n\n# Visualize labels\nplt.figure(figsize=(15, 3))\nhist = np.histogram(y, bins=np.arange(n_classes + 1))[0]\nplt.bar(np.arange(n_classes), hist)\nplt.xticks(np.arange(n_classes))\nplt.xlabel(\"label\")\nplt.ylabel(\"count\")\nplt.title(\"Single-trial labels\")\nplt.tight_layout()\n\n# Visualize codes\nVup = V.repeat(20, axis=1)  # upsample to better visualize the sharp edges\nplt.figure(figsize=(15, 8))\nplt.plot(np.arange(Vup.shape[1]) / (20 * fs), 2 * np.arange(n_classes) + Vup.T)\nfor i in range(1 + int(V.shape[1] / (fs / fr))):\n    plt.axvline(i / fr, c=\"k\", alpha=0.1)\nplt.yticks(2 * np.arange(n_classes), np.arange(n_classes))\nplt.xlabel(\"time [sec]\")\nplt.ylabel(\"code\")\nplt.title(\"Code time-series\")\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Epoch decoding\nIn this section, we will perform the classification of trials as a two-step approach. Firstly, we will classify\nso-called \"events\" at the \"epoch\" level. Subsequently, these epoch-level classifications are used (and integrated over\ntime) to classify full \"trials\".\n\nSpecifically, a trial contains the multi-channel EEG response to a visually presented stimulus. In the c-VEP domain,\nthe stimulus is a pseudo-random noise-code that encodes how each of the classes flashes (i.e., a 1-bit denotes a white\nbackground, a 0-bit denotes a black background). In this notebook, we call the 1-bits \"flashes\" and the 0-bits\n\"no-flashes\". In particular, the events we will work with are simply flashes versus no-flashes. Do note though, that\nmany other event-codings exist, for instance the \"duration\" events which considers two subsequent 1-bits to be\nanother event, while with the current flash versus no-flash encoding we assume that two consecutive 1-bits are the\nlinear summation of two identical responses (one a single bit shifted in time).\n\nWe thus need to slice the data into \"epochs\", which are windows of data around the individual events. Here, we choose\nto cut epochs rom the onset of the event, until 300 ms after the event (which should capture the classical Flash VEP).\nThese events will be labeled with the correct flash/no-flash label which comes from the codebook (`V`).\n\nThe sliced dataset `X` will be of shape trials by epochs (within one trial) by the number of channels by the number of\nsamples (in an epoch, not trial). Secondly, the sliced dataset contains labels `y` of shape trials by epochs,\nspecifically, a target class-label (flash versus no-flash) for each epoch in each trial.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Slice trials to epochs\nepoch_size = int(0.3 * fs)  # 300 ms\nstep_size = int(1 / 60 * fs)  # 1/60 ms\nX_sliced, y_sliced = pyntbci.utilities.trials_to_epochs(X, y, V, epoch_size, step_size)\nprint(\"X_sliced: shape:\", X_sliced.shape, \", type:\", X_sliced.dtype)\nprint(\"y_sliced: shape:\", y_sliced.shape, \", type:\", y_sliced.dtype)\n\n# Inspect sliced labels\nplt.figure(figsize=(15, 3))\nhist = np.histogram(y_sliced, bins=np.arange(2 + 1))[0]\nplt.bar(np.arange(2), hist)\nplt.xticks(np.arange(2), [\"non-target (no flash)\", \"target (flash)\"])\nplt.xlabel(\"label\")\nplt.ylabel(\"count\")\nplt.title(\"Epoch labels\")\n\nprint(\"Number of flash epochs:\", np.sum(y_sliced == 1))\nprint(\"Number of non-flash epochs:\", np.sum(y_sliced == 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Event-related potentials\nWith the sliced data, we can compute so-called event-related potentials (ERPs), i.e. averaged responses of epochs that\nhave the same label. Here, this will we an ERP for a flash epoch and one for non-flash epochs. Please note, these are\nnon-typical ERPs, as the epochs used here have a high amount of overlap. Specifically, the length of an epochs is 300\nms, while each epoch was sliced 1/60th ms after the previous one (i.e., a the stimulus presentation rate).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Compute ERPs\nerp_noflash = np.mean(X_sliced[y_sliced == 0, :, :], axis=0)\nerp_flash = np.mean(X_sliced[y_sliced == 1, :, :], axis=0)\n\n# Visualize temporal response per channel\nfig, ax = plt.subplots(n_channels, 1, figsize=(15, 2 * n_channels), sharex=True, sharey=True)\nfor i_channel in range(n_channels):\n    ax[i_channel].plot(np.arange(erp_noflash.shape[1]) / fs, erp_noflash[i_channel, :], label=\"non-target\")\n    ax[i_channel].plot(np.arange(erp_flash.shape[1]) / fs, erp_flash[i_channel, :], label=\"target\")\n    ax[i_channel].set_title(channels[i_channel])\n    ax[i_channel].set_ylabel(\"amplitude [V]\")\nax[0].legend()\nax[-1].set_xlabel(\"time [sec]\")\n\n# Visualize spatial response at a particular time-point\nfig, ax = plt.subplots(1, 2, figsize=(15, 3))\npyntbci.plotting.topoplot(erp_flash[:, int(0.150 * fs)], capfile, ax=ax[0])  # 150 ms\nax[0].set_title(\"target ERP at 150 ms\")\npyntbci.plotting.topoplot(erp_flash[:, int(0.175 * fs)], capfile, ax=ax[1])  # 175 ms\nax[1].set_title(\"target ERP at 175 ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Epoch to trial decoding with LDA\nThis section performs the two-step (epoch then trial) classification using a linear discriminant analysis (LDA)\nclassifier. This classifier classifies an epoch into flash or no-flash. With that information, an epoch-level accuracy\ncan be computed. To perform classification at the trial level, all classifications within the trial are integrated to\nperform a classification of the class label.\n\nClassification at the trial level is done by considering the prediction scores at the epoch level (i.e.\nprobabilities). These tell for each epoch within a trial the probability that a flash occurred. Ideally, this\nprobability is high if there was a flash (approaching 1) and 0 if not (approaching 0). This means that this\nprobability vector is in fact already an attempt to reconstruct the bit sequence itself. Therefore, with the vector of\nprobabilities for each of the epochs in a trial, we can simply compute a correlation with the codebook, to find the\ncode-sequence that best matches the probability vector (i.e. reconstructed code). Taking the argmax of the\ncorrelations yields the predicted class label. With these the trial level accuracy can be computed.\n\nNote, the LDA used here takes the entire 2D spatio-temporal feature matrix that is channels by samples, and flattens\nthese to a feature vector. Thus, LDA will learn a spatio-temporal filter to perform classification.\n\nTo estimate a generalization performance, a chronological cross-validation is performed below.\n\nNote, the dataset contains single-trials of 31.5 seconds long. For many participants in the dataset, if all data is\nused, this leads to 100% accuracy. A new parameter is introduced here, that cuts the single-trials to shorter lengths.\nIdeally, this parameter is explored, to estimate a so-called decoding curve.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set trial duration\nn_samples = int(4.2 * fs)\n\n# Set epoch size\nepoch_size = int(0.3 * fs)\nstep_size = int(1 / 60 * fs)\n\n# Setup cross-validation\nn_folds = 5\nfolds = np.repeat(np.arange(n_folds), n_trials / n_folds)\n\n# Set up codebook for trial classification\nn = int(np.ceil(n_samples / V.shape[1]))\n_V = np.tile(V, (1, n)).astype(\"float32\")[:, :n_samples - epoch_size:step_size]\n\n# Setup pipeline\npipeline = make_pipeline(\n    Vectorizer(),\n    LinearDiscriminantAnalysis(solver=\"eigen\", shrinkage=\"auto\"))\n\n# Loop folds\naccuracy_epoch = np.zeros(n_folds)\naccuracy_trial = np.zeros(n_folds)\nfor i_fold in range(n_folds):\n    # Split data to train and valid set\n    X_trn, y_trn = X[folds != i_fold, :, :n_samples], y[folds != i_fold]\n    X_tst, y_tst = X[folds == i_fold, :, :n_samples], y[folds == i_fold]\n\n    # Slice trials to epochs\n    X_sliced_trn, y_sliced_trn = pyntbci.utilities.trials_to_epochs(X_trn, y_trn, V, epoch_size, step_size)\n    X_sliced_tst, y_sliced_tst = pyntbci.utilities.trials_to_epochs(X_tst, y_tst, V, epoch_size, step_size)\n\n    # Train pipeline (on epoch level)\n    pipeline.fit(X_sliced_trn.reshape((-1, n_channels, epoch_size)), y_sliced_trn.flatten())\n\n    # Apply pipeline (on epoch level)\n    yh_sliced_tst = pipeline.predict(X_sliced_tst.reshape((-1, n_channels, epoch_size)))\n\n    # Compute accuracy (on epoch level)\n    accuracy_epoch[i_fold] = np.mean(yh_sliced_tst == y_sliced_tst.flatten())\n\n    # Apply pipeline (on trial level)\n    ph_tst = pipeline.predict_proba(X_sliced_tst.reshape((-1, n_channels, epoch_size)))[:, 1]\n    ph_tst = np.reshape(ph_tst, y_sliced_tst.shape)\n    rho = pyntbci.utilities.correlation(ph_tst, _V)\n    yh_tst = np.argmax(rho, axis=1)\n    accuracy_trial[i_fold] = np.mean(yh_tst == y_tst)\n\n# Print accuracy (average and standard deviation over folds)\nprint(\"LDA:\")\nprint(\"\\tEpoch: avg={:.1f} with std={:.2f}\".format(accuracy_epoch.mean(), accuracy_epoch.std()))\nprint(\"\\tTrial: avg={:.1f} with std={:.2f}\".format(accuracy_trial.mean(), accuracy_trial.std()))\n\n# Plot epoch accuracy (over folds)\nplt.figure(figsize=(15, 3))\nplt.bar(np.arange(n_folds), accuracy_epoch)\nplt.hlines(np.mean(accuracy_epoch), -.5, n_folds - 0.5, color=\"k\")\nplt.xlabel(\"(test) fold\")\nplt.ylabel(\"accuracy\")\nplt.title(f\"LDA: classification accuracy (epoch): avg={np.mean(accuracy_epoch):.2f} std={np.std(accuracy_epoch):.2f}\")\n\n# Plot trial accuracy (over folds)\nplt.figure(figsize=(15, 3))\nplt.bar(np.arange(n_folds), accuracy_trial)\nplt.hlines(np.mean(accuracy_trial), -.5, n_folds - 0.5, color=\"k\")\nplt.xlabel(\"(test) fold\")\nplt.ylabel(\"accuracy\")\nplt.title(f\"LDA: classification accuracy (trial): avg={np.mean(accuracy_trial):.2f} std={np.std(accuracy_trial):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Epoch to trial decoding with CCA and LDA\nThe code cell below performs the two-step (epoch then trial) classification using a canonical correlation analysis\n(CCA) and a linear discriminant analysis (LDA) classifier. CCA performs spatial filtering, and LDA classifies an epoch\ninto flash or no-flash. With that information, an epoch-level accuracy can be computed. To perform classification at\nthe trial level, all classifications within the trial are integrated to perform a classification of the class label.\n\nClassification at the trial level is done by considering the prediction scores at the epoch level (i.e.\nprobabilities). These tell for each epoch within a trial the probability that a flash occurred. Ideally, this\nprobability is high if there was a flash (approaching 1) and 0 if not (approaching 0). This means that this\nprobability vector is in fact already an attempt to reconstruct the bit sequence itself. Therefore, with the vector of\nprobabilities for each of the epochs in a trial, we can simply compute a correlation with the codebook, to find the\ncode-sequence that best matches the probability vector (i.e. reconstructed code). Taking the argmax of the\ncorrelations yields the predicted class label. With these the trial level accuracy can be computed.\n\nNote, other than in the previous section, here we first fit a CCA to learn a spatial filter, with which the 2D\nspatio-temporal data matrix of channels by samples can be projected down (i.e., spatially filtered) to a vector\n(i.e., a virtual channel) of samples. LDA will then only receive these samples as input, so will learn a temporal\nfilter only.\n\nTo estimate a generalization performance, a chronological cross-validation is performed below.\n\nNote, the dataset contains single-trials of 31.5 seconds long. For many participants in the dataset, if all data is\nused, this leads to 100% accuracy. A new parameter is introduced here, that cuts the single-trials to shorter lengths.\nIdeally, this parameter is explored, to estimate a so-called decoding curve.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set trial duration\nn_samples = int(4.2 * fs)\n\n# Set epoch size\nepoch_size = int(0.3 * fs)\nstep_size = int(1 / 60 * fs)\n\n# Setup cross-validation\nn_folds = 5\nfolds = np.repeat(np.arange(n_folds), n_trials / n_folds)\n\n# Set up codebook for trial classification\nn = int(np.ceil(n_samples / V.shape[1]))\n_V = np.tile(V, (1, n)).astype(\"float32\")[:, :n_samples - epoch_size:step_size]\n\n# Setup pipeline\ncca = pyntbci.transformers.CCA(n_components=1)\nvec = Vectorizer()\nlda = LinearDiscriminantAnalysis(solver=\"eigen\", shrinkage=\"auto\")\n\n# Loop folds\naccuracy_epoch = np.zeros(n_folds)\naccuracy_trial = np.zeros(n_folds)\nfor i_fold in range(n_folds):\n    # Split data to train and valid set\n    X_trn, y_trn = X[folds != i_fold, :, :n_samples], y[folds != i_fold]\n    X_tst, y_tst = X[folds == i_fold, :, :n_samples], y[folds == i_fold]\n\n    # Slice trials to epochs\n    X_sliced_trn, y_sliced_trn = pyntbci.utilities.trials_to_epochs(X_trn, y_trn, V, epoch_size, step_size)\n    X_sliced_tst, y_sliced_tst = pyntbci.utilities.trials_to_epochs(X_tst, y_tst, V, epoch_size, step_size)\n\n    # Train pipeline (on epoch level)\n    X_ = X_sliced_trn.reshape((-1, n_channels, epoch_size))\n    X_ = cca.fit_transform(X_, y_sliced_trn.flatten())[0]\n    X_ = vec.fit_transform(X_, y_sliced_trn.flatten())\n    lda.fit(X_, y_sliced_trn.flatten())\n\n    # Apply pipeline (on epoch level)\n    X_ = X_sliced_tst.reshape((-1, n_channels, epoch_size))\n    X_ = cca.transform(X_)[0]\n    X_ = vec.transform(X_)\n    yh_sliced_tst = lda.predict(X_)\n\n    # Compute accuracy (on epoch level)\n    accuracy_epoch[i_fold] = np.mean(yh_sliced_tst == y_sliced_tst.flatten())\n\n    # Apply pipeline (on trial level)\n    ph_tst = pipeline.predict_proba(X_sliced_tst.reshape((-1, n_channels, epoch_size)))[:, 1]\n    ph_tst = np.reshape(ph_tst, y_sliced_tst.shape)\n    rho = pyntbci.utilities.correlation(ph_tst, _V)\n    yh_tst = np.argmax(rho, axis=1)\n\n    # Compute accuracy (on trial level)\n    accuracy_trial[i_fold] = np.mean(yh_tst == y_tst)\n\n# Print accuracy (average and standard deviation over folds)\nprint(\"CCA+LDA:\")\nprint(\"\\tEpoch: avg={:.1f} with std={:.2f}\".format(accuracy_epoch.mean(), accuracy_epoch.std()))\nprint(\"\\tTrial: avg={:.1f} with std={:.2f}\".format(accuracy_trial.mean(), accuracy_trial.std()))\n\n# Plot epoch accuracy (over folds)\nplt.figure(figsize=(15, 3))\nplt.bar(np.arange(n_folds), accuracy_epoch)\nplt.hlines(np.mean(accuracy_epoch), -.5, n_folds - 0.5, color=\"k\")\nplt.xlabel(\"(test) fold\")\nplt.ylabel(\"accuracy\")\nplt.title(\"CCA+LDA: classification accuracy (epoch): \" +\n          f\"avg={np.mean(accuracy_epoch):.2f} std={np.std(accuracy_epoch):.2f}\")\n\n# Plot trial accuracy (over folds)\nplt.figure(figsize=(15, 3))\nplt.bar(np.arange(n_folds), accuracy_trial)\nplt.hlines(np.mean(accuracy_trial), -.5, n_folds - 0.5, color=\"k\")\nplt.xlabel(\"(test) fold\")\nplt.ylabel(\"accuracy\")\nplt.title(\"CCA+LDA: classification accuracy (trial): \" +\n          f\"avg={np.mean(accuracy_trial):.2f} std={np.std(accuracy_trial):.2f}\")\n\n# plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}